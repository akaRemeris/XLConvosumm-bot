{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6710432,"sourceType":"datasetVersion","datasetId":3867222}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:12:40.140482Z","iopub.execute_input":"2023-12-10T16:12:40.140841Z","iopub.status.idle":"2023-12-10T16:12:40.571206Z","shell.execute_reply.started":"2023-12-10T16:12:40.140810Z","shell.execute_reply":"2023-12-10T16:12:40.570328Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f7d255e11e431b9ae56a963fd37df8"}},"metadata":{}}]},{"cell_type":"code","source":"import wandb\n\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:12:46.632717Z","iopub.execute_input":"2023-12-10T16:12:46.633091Z","iopub.status.idle":"2023-12-10T16:12:53.199926Z","shell.execute_reply.started":"2023-12-10T16:12:46.633060Z","shell.execute_reply":"2023-12-10T16:12:53.199047Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project=\"BART-CNN-Convosumm\", entity=\"remeris\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:12:56.449738Z","iopub.execute_input":"2023-12-10T16:12:56.450701Z","iopub.status.idle":"2023-12-10T16:13:27.913716Z","shell.execute_reply.started":"2023-12-10T16:12:56.450666Z","shell.execute_reply":"2023-12-10T16:13:27.912724Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mremeris\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231210_161256-68syxthd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/remeris/BART-CNN-Convosumm/runs/68syxthd' target=\"_blank\">morning-plasma-6</a></strong> to <a href='https://wandb.ai/remeris/BART-CNN-Convosumm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/remeris/BART-CNN-Convosumm' target=\"_blank\">https://wandb.ai/remeris/BART-CNN-Convosumm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/remeris/BART-CNN-Convosumm/runs/68syxthd' target=\"_blank\">https://wandb.ai/remeris/BART-CNN-Convosumm/runs/68syxthd</a>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/remeris/BART-CNN-Convosumm/runs/68syxthd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7a2b8d5cebf0>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install peft\n!pip install evaluate\n!pip install rouge_score","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-10T16:13:27.915213Z","iopub.execute_input":"2023-12-10T16:13:27.915556Z","iopub.status.idle":"2023-12-10T16:14:07.445241Z","shell.execute_reply.started":"2023-12-10T16:13:27.915530Z","shell.execute_reply":"2023-12-10T16:14:07.443971Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/82/cc/bf022d6bc3996a5939c3ee39bde2b0e1f8bf6cea6ef9c9cdaf1639586237/peft-0.7.0-py3-none-any.whl.metadata\n  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.35.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.7.0-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.7.0\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.12.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.19.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.24.3)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=8606b30480948b6b4beb4c60e1738cc40d4b9b87f9ec0b64674a6c32b776a00c\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BartTokenizerFast\nfrom transformers import BartConfig\nfrom datasets import Dataset, DatasetDict\nfrom copy import deepcopy\nfrom transformers import BartForConditionalGeneration\nimport nltk\nimport numpy as np\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import DataCollatorForSeq2Seq\nimport evaluate\nimport random\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:07.447502Z","iopub.execute_input":"2023-12-10T16:14:07.447871Z","iopub.status.idle":"2023-12-10T16:14:26.212432Z","shell.execute_reply.started":"2023-12-10T16:14:07.447837Z","shell.execute_reply":"2023-12-10T16:14:26.211271Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"MODELS_PATH = './models/'\nDATASETS_PATH = '/kaggle/input/'\nDATASET_VERSION = 'arg-filtered/'","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:26.214784Z","iopub.execute_input":"2023-12-10T16:14:26.215477Z","iopub.status.idle":"2023-12-10T16:14:26.220968Z","shell.execute_reply.started":"2023-12-10T16:14:26.215447Z","shell.execute_reply":"2023-12-10T16:14:26.219883Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def init_random_seed(value=42):\n    random.seed(value)\n    np.random.seed(value)\n    torch.manual_seed(value)\n    torch.cuda.manual_seed(value)\ninit_random_seed()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:26.222346Z","iopub.execute_input":"2023-12-10T16:14:26.222785Z","iopub.status.idle":"2023-12-10T16:14:26.249215Z","shell.execute_reply.started":"2023-12-10T16:14:26.222753Z","shell.execute_reply":"2023-12-10T16:14:26.248112Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_dict = {}\nfor dataset_type in ['train', 'val', 'test']:\n    seq_type_dict = {}\n    for seq_type in ['source', 'target']:\n        with open(DATASETS_PATH + DATASET_VERSION + dataset_type + '.' + seq_type, 'r') as fstream:\n            seq_type_dict[seq_type] = fstream.readlines()\n    data_dict[dataset_type] = Dataset.from_dict(seq_type_dict)\n    \nraw_datasets = DatasetDict(data_dict)\n\ntokenizer = BartTokenizerFast.from_pretrained('facebook/bart-large')\n\nMAX_SEQ_LEN = 2048\ndef preprocess_function(examples, max_length):\n    model_inputs = tokenizer(text=examples[\"source\"], max_length=max_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    labels = tokenizer(text_target=examples[\"target\"], max_length=max_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\nlong_tokenized_datasets = raw_datasets.map(lambda x: preprocess_function(x, 2048), batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:26.250714Z","iopub.execute_input":"2023-12-10T16:14:26.251067Z","iopub.status.idle":"2023-12-10T16:14:31.490761Z","shell.execute_reply.started":"2023-12-10T16:14:26.251035Z","shell.execute_reply":"2023-12-10T16:14:31.489680Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24b8fc36575e4f8fa5b346a22763b0d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed7ad80337824130881d595bfb4f82af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"223eaf6da27c47348f2ced1c9655866c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8675010563d54609a33b35e9f4d10e7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91f3e1c1724642c892994133c8296680"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86c3a9c94db64469aaf16c9fac738f07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674bb50d296c4abaab08ba3d0d714fc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1758c1353f95483e9fb6310a6a177757"}},"metadata":{}}]},{"cell_type":"code","source":"def get_longer_model(model):\n    cur_state = model.state_dict()\n    encoder_pos_embs = cur_state['model.encoder.embed_positions.weight']\n    to_append = encoder_pos_embs[2:]\n    new_encoder_pos = torch.cat((encoder_pos_embs, to_append))\n    cur_state['model.encoder.embed_positions.weight'] = new_encoder_pos\n    cur_state['model.decoder.embed_positions.weight'] = new_encoder_pos\n    cfg = model.config\n    cfg.max_position_embeddings = cfg.max_position_embeddings * 2\n    new_model = BartForConditionalGeneration(cfg)\n    new_model.load_state_dict(cur_state, strict=True)\n    return new_model","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:31.492265Z","iopub.execute_input":"2023-12-10T16:14:31.493020Z","iopub.status.idle":"2023-12-10T16:14:31.501780Z","shell.execute_reply.started":"2023-12-10T16:14:31.492978Z","shell.execute_reply":"2023-12-10T16:14:31.500652Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load('rouge')\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n    \n    # Note that other metrics may not have a `use_aggregator` parameter\n    # and thus will return a list, computing a metric for each sentence.\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    # Extract a few results\n    result = {key: value * 100 for key, value in result.items()}\n    \n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    \n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:31.503092Z","iopub.execute_input":"2023-12-10T16:14:31.504195Z","iopub.status.idle":"2023-12-10T16:14:33.106083Z","shell.execute_reply.started":"2023-12-10T16:14:31.504163Z","shell.execute_reply":"2023-12-10T16:14:33.105038Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd59938a22cc43c1bfd2fe967d9509ad"}},"metadata":{}}]},{"cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:14:33.107551Z","iopub.execute_input":"2023-12-10T16:14:33.107908Z","iopub.status.idle":"2023-12-10T16:15:20.740706Z","shell.execute_reply.started":"2023-12-10T16:14:33.107859Z","shell.execute_reply":"2023-12-10T16:15:20.739649Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7f074ff2444fe6ae797a8d1e2f966e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d915693313a246cfb47456052663d1bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b4608de3cc41d5a80e1e098c891f7d"}},"metadata":{}}]},{"cell_type":"code","source":"model = get_longer_model(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:15:20.744160Z","iopub.execute_input":"2023-12-10T16:15:20.744446Z","iopub.status.idle":"2023-12-10T16:15:29.458999Z","shell.execute_reply.started":"2023-12-10T16:15:20.744420Z","shell.execute_reply":"2023-12-10T16:15:29.457939Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='BART-CNN-Convosumm',\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    predict_with_generate=True, \n    evaluation_strategy='epoch',\n    do_train=True,\n    do_eval=True,\n    learning_rate=3e-5,\n    label_smoothing_factor=0.1,\n    warmup_steps=1,\n    lr_scheduler_type='polynomial',\n    weight_decay=0.01,\n    num_train_epochs=7,\n    push_to_hub=True,\n    gradient_accumulation_steps=20,\n    load_best_model_at_end=True,\n    metric_for_best_model='rouge1',\n    save_total_limit=1,\n    save_strategy='epoch',\n    logging_strategy='epoch',\n    report_to=\"wandb\",\n    hub_model_id='Remeris/BART-CNN-Convosumm',\n    hub_strategy='end'\n    \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:15:29.460528Z","iopub.execute_input":"2023-12-10T16:15:29.460943Z","iopub.status.idle":"2023-12-10T16:15:29.499858Z","shell.execute_reply.started":"2023-12-10T16:15:29.460886Z","shell.execute_reply":"2023-12-10T16:15:29.498796Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"short_data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n\ntrainer = Seq2SeqTrainer(\n    tokenizer=tokenizer,\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=long_tokenized_datasets['train'],\n    eval_dataset=long_tokenized_datasets['val'],\n    data_collator=short_data_collator\n)\n\ntrainer.train()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:15:29.501058Z","iopub.execute_input":"2023-12-10T16:15:29.501398Z","iopub.status.idle":"2023-12-10T16:29:27.602303Z","shell.execute_reply.started":"2023-12-10T16:15:29.501367Z","shell.execute_reply":"2023-12-10T16:29:27.601325Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [70/70 13:48, Epoch 6/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>6.207000</td>\n      <td>4.265142</td>\n      <td>32.334100</td>\n      <td>7.812000</td>\n      <td>20.041100</td>\n      <td>29.484900</td>\n      <td>77.380000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4.024800</td>\n      <td>3.990273</td>\n      <td>36.078700</td>\n      <td>11.044700</td>\n      <td>21.359600</td>\n      <td>33.290300</td>\n      <td>130.580000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.593300</td>\n      <td>3.901969</td>\n      <td>34.293100</td>\n      <td>11.203600</td>\n      <td>20.793500</td>\n      <td>30.836100</td>\n      <td>140.020000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.308600</td>\n      <td>3.871231</td>\n      <td>38.484200</td>\n      <td>11.994700</td>\n      <td>23.491300</td>\n      <td>34.434700</td>\n      <td>85.780000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.112000</td>\n      <td>3.869993</td>\n      <td>38.652000</td>\n      <td>11.831500</td>\n      <td>23.520800</td>\n      <td>34.599800</td>\n      <td>76.200000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.993300</td>\n      <td>3.880933</td>\n      <td>38.660000</td>\n      <td>12.333700</td>\n      <td>23.439400</td>\n      <td>35.197600</td>\n      <td>83.260000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.834000</td>\n      <td>3.879697</td>\n      <td>38.625200</td>\n      <td>12.255600</td>\n      <td>23.902000</td>\n      <td>34.632400</td>\n      <td>81.280000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=70, training_loss=3.7247077396937778, metrics={'train_runtime': 816.046, 'train_samples_per_second': 1.724, 'train_steps_per_second': 0.086, 'total_flos': 1568867334709248.0, 'train_loss': 3.7247077396937778, 'epoch': 6.97})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.predict(long_tokenized_datasets['test'])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:29:27.603563Z","iopub.execute_input":"2023-12-10T16:29:27.604254Z","iopub.status.idle":"2023-12-10T16:34:43.215490Z","shell.execute_reply.started":"2023-12-10T16:29:27.604226Z","shell.execute_reply":"2023-12-10T16:34:43.214471Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[2, 0, 0, ..., 1, 1, 1],\n       [2, 0, 0, ..., 1, 1, 1],\n       [2, 0, 0, ..., 1, 1, 1],\n       ...,\n       [2, 0, 0, ..., 1, 1, 1],\n       [2, 0, 0, ..., 1, 1, 1],\n       [2, 0, 0, ..., 1, 1, 1]]), label_ids=array([[    0, 45331,   268, ...,     1,     1,     1],\n       [    0, 29182, 22800, ...,     1,     1,     1],\n       [    0,  2895, 40471, ...,     1,     1,     1],\n       ...,\n       [    0, 10787,  2003, ...,     1,     1,     1],\n       [    0,   133, 40471, ...,     1,     1,     1],\n       [    0,  2895, 40471, ...,     1,     1,     1]]), metrics={'test_loss': 3.834308624267578, 'test_rouge1': 38.3642, 'test_rouge2': 12.2056, 'test_rougeL': 23.7782, 'test_rougeLsum': 34.3959, 'test_gen_len': 84.132, 'test_runtime': 315.5988, 'test_samples_per_second': 0.792, 'test_steps_per_second': 0.792})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:34:43.217374Z","iopub.execute_input":"2023-12-10T16:34:43.217758Z","iopub.status.idle":"2023-12-10T16:35:54.859505Z","shell.execute_reply.started":"2023-12-10T16:34:43.217719Z","shell.execute_reply":"2023-12-10T16:35:54.858264Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8675625bdea4fd49b7e0dcf98de6d3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa3cb63428fe40f890c81ae74abfccf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b6be7c359ac49d8b540cb30790b6bff"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Remeris/BART-CNN-Convosumm/tree/main/'"},"metadata":{}}]},{"cell_type":"code","source":"translated_source = \"\"\"\nI personally don’t know how to resist shootings, if only to install a metal detector, because the cleaning lady Baba Zina is unlikely to cope alone It’s hard to believe, but a person needs to be brought to this level. good psychologists are needed at school, team building class when a person gets to know the people around him better, he begins to understand what and why, their characters, begins to make friends and finds common topics for communication if this is not the case, a person who is uncommunicative ends up in a kind of bubble, because he himself cannot start communication, and perhaps he doesn’t want to, because he thinks that they are different although children are essentially very similar, they are simply formed in the same society, the only difference between them is their parents and hobby groups I’m not sure that’s the problem. I gave a fuck about everyone at school. But there was one in my class who was very close to shooting everyone and everything if he had a gun at hand. but not because he was quiet I agree about psychologists here. if we talk about school shooting, it’s always a combination of factors there is no school shooting just because of parents or just because of school a person, whatever one may say, is a social creature, wants to chat, share joy, and maybe grief. When there is no one and nowhere to share emotions, it becomes difficult plus children are always prone to extremes. As a child, I couldn’t even think that grades in quarters would never be useful in life. I thought that somehow they would move on. I can’t even imagine that in principle you don’t have to go to school, just pass the exams and learn the topic from the textbook and everything will be okay but everyone told us that you should teach, otherwise you’ll go to a workhouse, or sweep the street, so-so motivation for an intimidated child apparently I was the wrong child. \"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:35:54.861322Z","iopub.execute_input":"2023-12-10T16:35:54.861718Z","iopub.status.idle":"2023-12-10T16:35:54.869961Z","shell.execute_reply.started":"2023-12-10T16:35:54.861683Z","shell.execute_reply":"2023-12-10T16:35:54.868944Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"inf_input = tokenizer(translated_source, max_length=2048, return_tensors=\"pt\", truncation=True)\nmodel_output = model.generate(input_ids=inf_input.input_ids.cuda())\ntokenizer.batch_decode(model_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:35:54.871261Z","iopub.execute_input":"2023-12-10T16:35:54.871541Z","iopub.status.idle":"2023-12-10T16:35:56.066348Z","shell.execute_reply.started":"2023-12-10T16:35:54.871515Z","shell.execute_reply":"2023-12-10T16:35:56.065095Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'Most of the commenters agree that psychologists are needed at school to help students cope with social situations such as school shootings. A few commenters say that they did not know how to resist shootings. One commenter says that a person needs to be more social, while another says that it’s a combination of factors, with one commenter saying that children are very similar to each other.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}